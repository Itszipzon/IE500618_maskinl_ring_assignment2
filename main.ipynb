{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
      "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
      "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
      "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
      "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
      "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
      "\n",
      "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
      "0                   0.0           0.0     0.0  ...            1.0   \n",
      "1                   0.0           1.0     0.0  ...            0.0   \n",
      "2                   0.0           0.0     1.0  ...            1.0   \n",
      "3                   0.0           1.0     1.0  ...            1.0   \n",
      "4                   0.0           1.0     1.0  ...            1.0   \n",
      "\n",
      "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
      "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
      "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
      "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
      "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
      "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
      "\n",
      "   Income  \n",
      "0     3.0  \n",
      "1     1.0  \n",
      "2     8.0  \n",
      "3     6.0  \n",
      "4     4.0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, recall_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "file_path = 'diabetes_binary_classification_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE Ranking of Features: [ 1  1  2  1 16 11  6 12 10 17  3 14 15  1 13  7  8  4  1  9  5]\n",
      "\n",
      "Model: Logistic Regression\n",
      "Confusion Matrix:\n",
      "[[64027  1473]\n",
      " [ 8933  1671]]\n",
      "Accuracy: 0.8633\n",
      "Recall (minimize false negatives): 0.1576\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92     65500\n",
      "           1       0.53      0.16      0.24     10604\n",
      "\n",
      "    accuracy                           0.86     76104\n",
      "   macro avg       0.70      0.57      0.58     76104\n",
      "weighted avg       0.83      0.86      0.83     76104\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "Confusion Matrix:\n",
      "[[57046  8454]\n",
      " [ 7112  3492]]\n",
      "Accuracy: 0.7955\n",
      "Recall (minimize false negatives): 0.3293\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88     65500\n",
      "           1       0.29      0.33      0.31     10604\n",
      "\n",
      "    accuracy                           0.80     76104\n",
      "   macro avg       0.59      0.60      0.59     76104\n",
      "weighted avg       0.81      0.80      0.80     76104\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Confusion Matrix:\n",
      "[[63549  1951]\n",
      " [ 8752  1852]]\n",
      "Accuracy: 0.8594\n",
      "Recall (minimize false negatives): 0.1747\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     65500\n",
      "           1       0.49      0.17      0.26     10604\n",
      "\n",
      "    accuracy                           0.86     76104\n",
      "   macro avg       0.68      0.57      0.59     76104\n",
      "weighted avg       0.82      0.86      0.83     76104\n",
      "\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Confusion Matrix:\n",
      "[[64104  1396]\n",
      " [ 8867  1737]]\n",
      "Accuracy: 0.8651\n",
      "Recall (minimize false negatives): 0.1638\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93     65500\n",
      "           1       0.55      0.16      0.25     10604\n",
      "\n",
      "    accuracy                           0.87     76104\n",
      "   macro avg       0.72      0.57      0.59     76104\n",
      "weighted avg       0.83      0.87      0.83     76104\n",
      "\n",
      "\n",
      "Feature Importance from Random Forest:\n",
      " BMI                     0.184999\n",
      "Age                     0.121244\n",
      "Income                  0.097986\n",
      "PhysHlth                0.084517\n",
      "GenHlth                 0.071248\n",
      "Education               0.068916\n",
      "MentHlth                0.063675\n",
      "HighBP                  0.044248\n",
      "Fruits                  0.033147\n",
      "Smoker                  0.032846\n",
      "Sex                     0.028212\n",
      "PhysActivity            0.026739\n",
      "HighChol                0.026584\n",
      "Veggies                 0.026472\n",
      "DiffWalk                0.023272\n",
      "HeartDiseaseorAttack    0.018418\n",
      "NoDocbcCost             0.014831\n",
      "Stroke                  0.012662\n",
      "AnyHealthcare           0.008397\n",
      "HvyAlcoholConsump       0.008031\n",
      "CholCheck               0.003557\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Diabetes_binary' into binary classification (0 = no diabetes, 1 = prediabetes or diabetes)\n",
    "df['Diabetes_binary'] = df['Diabetes_binary'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "\n",
    "# Handle categorical variables (most are already numerical, no need for additional encoding)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('Diabetes_binary', axis=1)  # Features\n",
    "y = df['Diabetes_binary']               # Target\n",
    "\n",
    "# Handle missing values (if any)\n",
    "imputer = SimpleImputer(strategy='mean')  # You can change the strategy as needed\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Feature scaling (especially for models like Logistic Regression)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Feature Importance using RFE (Recursive Feature Elimination)\n",
    "model_lr = LogisticRegression(max_iter=1000)\n",
    "rfe = RFE(model_lr, n_features_to_select=5)  # Select the top 5 most important features\n",
    "rfe = rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the ranking of features\n",
    "print(f'RFE Ranking of Features: {rfe.ranking_}')\n",
    "\n",
    "# Train various models and compare them\n",
    "# Initialize models\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "gradient_boost = GradientBoostingClassifier()\n",
    "\n",
    "# Train the models and predict\n",
    "models = {'Logistic Regression': log_reg, \n",
    "          'Decision Tree': decision_tree, \n",
    "          'Random Forest': random_forest, \n",
    "          'Gradient Boosting': gradient_boost}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Confusion Matrix and Classification Report\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'\\nModel: {name}')\n",
    "    print(f'Confusion Matrix:\\n{cm}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Recall (minimize false negatives): {recall:.4f}')\n",
    "    print(f'Classification Report:\\n{classification_report(y_test, y_pred)}')\n",
    "\n",
    "# Feature importance from Random Forest\n",
    "importances = random_forest.feature_importances_\n",
    "feature_importance = pd.Series(importances, index=df.drop('Diabetes_binary', axis=1).columns)\n",
    "feature_importance = feature_importance.sort_values(ascending=False)\n",
    "print(\"\\nFeature Importance from Random Forest:\\n\", feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
